{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b05df67",
   "metadata": {},
   "source": [
    "# Heart Disease Prediction - Machine Learning Project\n",
    "\n",
    "In this notebook, we'll build a machine learning model to predict heart disease using the UCI Heart Disease dataset. We'll perform exploratory data analysis, preprocess the data, train multiple models, and evaluate their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c54f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed926c9",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0c6511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('data/heart_disease.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af785262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values:\")\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# Statistical summary\n",
    "print(\"\\nStatistical Summary:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f39db82",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f04cb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of target variable\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(data=df, x='target')\n",
    "plt.title('Distribution of Heart Disease')\n",
    "plt.xlabel('Heart Disease (0 = No, 1+ = Yes)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Convert target to binary (0 = No disease, 1 = Disease)\n",
    "df['target'] = df['target'].apply(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "print(\"Target distribution after conversion:\")\n",
    "print(df['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852a8c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age distribution by heart disease\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(data=df, x='age', hue='target', bins=30, kde=True)\n",
    "plt.title('Age Distribution by Heart Disease')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136f649a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sex distribution by heart disease\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(data=df, x='sex', hue='target')\n",
    "plt.title('Heart Disease by Sex')\n",
    "plt.xlabel('Sex (0 = Female, 1 = Male)')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Heart Disease', labels=['No', 'Yes'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9258d98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chest pain type distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=df, x='cp', hue='target')\n",
    "plt.title('Heart Disease by Chest Pain Type')\n",
    "plt.xlabel('Chest Pain Type')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Heart Disease', labels=['No', 'Yes'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d78c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "plt.figure(figsize=(14, 10))\n",
    "correlation_matrix = df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529775a7",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52317a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Training set shape:\", X_train_scaled.shape)\n",
    "print(\"Test set shape:\", X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e825ae8",
   "metadata": {},
   "source": [
    "## 4. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f192e15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': SVC(probability=True, random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'roc_auc': roc_auc,\n",
    "        'predictions': y_pred,\n",
    "        'probabilities': y_pred_proba\n",
    "    }\n",
    "    \n",
    "    print(f\"{name} Results:\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  ROC-AUC: {roc_auc:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec8c7bf",
   "metadata": {},
   "source": [
    "## 5. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5585c392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performances\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'Accuracy': [results[model]['accuracy'] for model in results.keys()],\n",
    "    'ROC-AUC': [results[model]['roc_auc'] for model in results.keys()]\n",
    "})\n",
    "\n",
    "print(\"Model Comparison:\")\n",
    "print(comparison_df)\n",
    "\n",
    "# Visualize model comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "x = np.arange(len(results))\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(x - width/2, comparison_df['Accuracy'], width, label='Accuracy')\n",
    "ax.bar(x + width/2, comparison_df['ROC-AUC'], width, label='ROC-AUC')\n",
    "\n",
    "ax.set_xlabel('Models')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Model Performance Comparison')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(comparison_df['Model'])\n",
    "ax.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a4cf8d",
   "metadata": {},
   "source": [
    "## 6. Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd384f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrices for all models\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for i, (name, result) in enumerate(results.items()):\n",
    "    cm = confusion_matrix(y_test, result['predictions'])\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i])\n",
    "    axes[i].set_title(f'{name} Confusion Matrix')\n",
    "    axes[i].set_xlabel('Predicted')\n",
    "    axes[i].set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e650911",
   "metadata": {},
   "source": [
    "## 7. ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7adf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves for all models\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for name, result in results.items():\n",
    "    fpr, tpr, _ = roc_curve(y_test, result['probabilities'])\n",
    "    plt.plot(fpr, tpr, label=f\"{name} (AUC = {result['roc_auc']:.3f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd31f3b3",
   "metadata": {},
   "source": [
    "## 8. Feature Importance (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64344a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from Random Forest\n",
    "rf_model = results['Random Forest']['model']\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importance (Random Forest):\")\n",
    "print(feature_importance)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(data=feature_importance, y='feature', x='importance')\n",
    "plt.title('Feature Importance (Random Forest)')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90566a3",
   "metadata": {},
   "source": [
    "## 9. Save Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c016e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best model based on ROC-AUC score\n",
    "best_model_name = max(results, key=lambda x: results[x]['roc_auc'])\n",
    "best_model = results[best_model_name]['model']\n",
    "\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"ROC-AUC Score: {results[best_model_name]['roc_auc']:.4f}\")\n",
    "\n",
    "# Save the best model and scaler\n",
    "import joblib\n",
    "joblib.dump(best_model, 'model/best_model.pkl')\n",
    "joblib.dump(scaler, 'model/scaler.pkl')\n",
    "joblib.dump(imputer, 'model/imputer.pkl')\n",
    "\n",
    "print(\"\\nModel and preprocessing objects saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbb14ae",
   "metadata": {},
   "source": [
    "## 10. Model Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1bfc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_heart_disease(age, sex, cp, trestbps, chol, fbs, restecg, thalach, exang, oldpeak, slope, ca, thal):\n",
    "    \"\"\"\n",
    "    Predict heart disease risk for a patient based on input features.\n",
    "    \"\"\"\n",
    "    # Load the trained model and preprocessing objects\n",
    "    model = joblib.load('model/best_model.pkl')\n",
    "    scaler = joblib.load('model/scaler.pkl')\n",
    "    imputer = joblib.load('model/imputer.pkl')\n",
    "    \n",
    "    # Create feature array\n",
    "    features = np.array([[age, sex, cp, trestbps, chol, fbs, restecg, thalach, exang, oldpeak, slope, ca, thal]])\n",
    "    \n",
    "    # Apply preprocessing\n",
    "    features_imputed = imputer.transform(features)\n",
    "    features_scaled = scaler.transform(features_imputed)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(features_scaled)[0]\n",
    "    probability = model.predict_proba(features_scaled)[0][1]\n",
    "    \n",
    "    return prediction, probability\n",
    "\n",
    "# Example prediction\n",
    "prediction, probability = predict_heart_disease(\n",
    "    age=63, sex=1, cp=1, trestbps=145, chol=233, fbs=1, restecg=2, \n",
    "    thalach=150, exang=0, oldpeak=2.3, slope=3, ca=0, thal=6\n",
    ")\n",
    "\n",
    "print(f\"Prediction: {'Heart Disease' if prediction == 1 else 'No Heart Disease'}\")\n",
    "print(f\"Probability of Heart Disease: {probability:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021c338a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this notebook, we have:\n",
    "1. Loaded and explored the UCI Heart Disease dataset\n",
    "2. Performed exploratory data analysis with visualizations\n",
    "3. Preprocessed the data (handled missing values, scaled features)\n",
    "4. Trained and evaluated three machine learning models (Random Forest, SVM, Logistic Regression)\n",
    "5. Compared model performances using accuracy and ROC-AUC scores\n",
    "6. Analyzed feature importance using Random Forest\n",
    "7. Saved the best performing model for deployment\n",
    "8. Created a prediction function for making inference on new data\n",
    "\n",
    "The best model can now be deployed as a web service using Flask."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
